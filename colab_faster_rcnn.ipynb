{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение Faster R-CNN (Colab Notebook)\n\n",
    "Этот блокнот повторяет функциональность скрипта `colab_faster_rcnn.py` и предназначен для запуска в Google Colab.\n",
    "В нём реализованы обучение, вычисление mAP (через `torchmetrics`) и построение графиков.\n",
    "Формат датасета: для каждой картинки `.png` рядом файл `.txt` с YOLO-строками `<class_id> <x_center> <y_center> <width> <height>`.\n",
    "Данные должны быть заранее разложены по подпапкам `train/`, `val/`, `test` с подкаталогами `images/` и `labels/`.\n"
    "# Обучение Faster R-CNN (Colab Notebook)\n",
    "\n",
    "Этот блокнот повторяет функциональность скрипта `colab_faster_rcnn.py` и предназначен для запуска в Google Colab.\\n",
    "В нём есть разбиение датасета на train/val/test, обучение, вычисление mAP (через `torchmetrics`) и построение графиков.\\n",
    "Формат датасета: для каждой картинки `.png` рядом файл `.txt` с YOLO-строками `<class_id> <x_center> <y_center> <width> <height>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установите дополнительные зависимости (при необходимости)\n",
    "# В Colab этот блок можно выполнить один раз\n",
    "!pip install -q torchmetrics==1.4.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import convert_image_dtype\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# Метрики и графики\n",
    "try:\n",
    "    import torchmetrics\n",
    "    from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "except Exception:  # noqa: BLE001\n",
    "    torchmetrics = None\n",
    "    MeanAveragePrecision = None\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainConfig:\n",
    "    data_dir: str\n",
    "    output_dir: str = \"runs\"\n",
    "    train_ratio: float = 0.7\n",
    "    val_ratio: float = 0.15\n",
    "    batch_size: int = 2\n",
    "    num_epochs: int = 10\n",
    "    lr: float = 5e-4\n",
    "    weight_decay: float = 1e-4\n",
    "    seed: int = 42\n",
    "    num_workers: int = 2\n",
    "\n"
    "    num_workers: int = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloTxtDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Кастомный датасет для пар .png/.txt с YOLO-аннотациями.\n",
    "    Возвращает изображение тензор и словарь target, совместимый с torchvision detection API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, samples: List[Tuple[str, str]]):\n",
    "        self.samples = samples\n",
    "        self.transform = transforms.Compose([transforms.ConvertImageDtype(torch.float32)])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, Dict[str, Any]]:\n",
    "        img_path, txt_path = self.samples[idx]\n",
    "        image = read_image(img_path)\n",
    "        c, h, w = image.shape\n",
    "\n",
    "        boxes: List[List[float]] = []\n",
    "        labels: List[int] = []\n",
    "\n",
    "        if os.path.exists(txt_path):\n",
    "            with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    if not line.strip():\n",
    "                        continue\n",
    "                    parts = line.strip().split()\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center, y_center, bw, bh = map(float, parts[1:])\n",
    "                    # денормализуем и переводим в xyxy\n",
    "                    x_min = (x_center - bw / 2) * w\n",
    "                    y_min = (y_center - bh / 2) * h\n",
    "                    x_max = (x_center + bw / 2) * w\n",
    "                    y_max = (y_center + bh / 2) * h\n",
    "                    boxes.append([x_min, y_min, x_max, y_max])\n",
    "                    labels.append(class_id + 1)  # +1 потому что 0 — фон у Faster R-CNN\n",
    "\n",
    "        boxes_tensor = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.int64)\n",
    "        target: Dict[str, Any] = {\n",
    "            \"boxes\": boxes_tensor,\n",
    "            \"labels\": labels_tensor,\n",
    "            \"image_id\": torch.tensor([idx]),\n",
    "        }\n",
    "\n",
    "        image = convert_image_dtype(image, torch.float32)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch: List[Tuple[torch.Tensor, Dict[str, Any]]]):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "def list_split_dataset(data_dir: str, split: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Возвращает список пар (путь_к_png, путь_к_txt) для подпапки split.\n",
    "\n",
    "    Ожидаем структуру:\n",
    "    dataset/\n",
    "      train/images/*.png\n",
    "      train/labels/*.txt\n",
    "      val/images/*.png\n",
    "      val/labels/*.txt\n",
    "      test/images/*.png\n",
    "      test/labels/*.txt\n",
    "    \"\"\"\n",
    "\n",
    "    img_dir = os.path.join(data_dir, split, \"images\")\n",
    "    lbl_dir = os.path.join(data_dir, split, \"labels\")\n",
    "    if not os.path.isdir(img_dir):\n",
    "        raise RuntimeError(f\"Не найден каталог с изображениями: {img_dir}\")\n",
    "    if not os.path.isdir(lbl_dir):\n",
    "        raise RuntimeError(f\"Не найден каталог с разметкой: {lbl_dir}\")\n",
    "\n",
    "    samples: List[Tuple[str, str]] = []\n",
    "    for fname in os.listdir(img_dir):\n",
    "        if fname.lower().endswith(\".png\"):\n",
    "            base = os.path.splitext(fname)[0]\n",
    "            img_path = os.path.join(img_dir, fname)\n",
    "            txt_path = os.path.join(lbl_dir, base + \".txt\")\n",
    "            samples.append((img_path, txt_path))\n",
    "    samples.sort()\n",
    "    if not samples:\n",
    "        raise RuntimeError(f\"В каталоге {img_dir} не найдено изображений .png\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "def list_dataset(data_dir: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"Ищем все .png и соответствующие им .txt рядом.\"\"\"\n",
    "    samples: List[Tuple[str, str]] = []\n",
    "    for fname in os.listdir(data_dir):\n",
    "        if fname.lower().endswith(\".png\"):\n",
    "            base = os.path.splitext(fname)[0]\n",
    "            img_path = os.path.join(data_dir, fname)\n",
    "            txt_path = os.path.join(data_dir, base + \".txt\")\n",
    "            samples.append((img_path, txt_path))\n",
    "    samples.sort()\n",
    "    return samples\n",
    "\n",
    "\n",
    "def split_dataset(samples: List[Tuple[str, str]], train_ratio: float, val_ratio: float, seed: int):\n",
    "    random.seed(seed)\n",
    "    random.shuffle(samples)\n",
    "    n = len(samples)\n",
    "    n_train = int(n * train_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "    train_samples = samples[:n_train]\n",
    "    val_samples = samples[n_train:n_train + n_val]\n",
    "    test_samples = samples[n_train + n_val:]\n",
    "    return train_samples, val_samples, test_samples\n",
    "\n",
    "\n",
    "def build_model(num_classes: int):\n",
    "    model = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n"
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, data_loader, device):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    for images, targets in data_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(losses.item())\n",
    "    return epoch_losses\n",
    "\n",
    "\n",
    "def evaluate_map(model, data_loader, device):\n",
    "    if MeanAveragePrecision is None:\n",
    "        print(\"TorchMetrics не установлен. Запустите !pip install torchmetrics\")\n",
    "        return None\n",
    "    metric = MeanAveragePrecision()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            outputs = model(images)\n",
    "            outputs_cpu = []\n",
    "            for out in outputs:\n",
    "                outputs_cpu.append(\n",
    "                    {\n",
    "                        \"boxes\": out[\"boxes\"].cpu(),\n",
    "                        \"scores\": out[\"scores\"].cpu(),\n",
    "                        \"labels\": out[\"labels\"].cpu(),\n",
    "                    }\n",
    "                )\n",
    "            targets_cpu = []\n",
    "            for t in targets:\n",
    "                targets_cpu.append({\"boxes\": t[\"boxes\"], \"labels\": t[\"labels\"]})\n",
    "            metric.update(outputs_cpu, targets_cpu)\n",
    "    return metric.compute()\n",
    "\n",
    "\n",
    "def plot_curves(history: Dict[str, List[float]], output_dir: str):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history.get(\"train_loss\", []), label=\"Train loss\")\n",
    "    if \"val_map\" in history:\n",
    "        plt.plot(history[\"val_map\"], label=\"Val mAP\")\n",
    "    plt.xlabel(\"Эпоха\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(output_dir, \"training_curves.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    print(f\"График сохранен в {plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(cfg: TrainConfig):\n",
    "    print(\"Конфиг:\", asdict(cfg))\n",
    "    train_samples = list_split_dataset(cfg.data_dir, \"train\")\n",
    "    val_samples = list_split_dataset(cfg.data_dir, \"val\")\n",
    "    test_samples = list_split_dataset(cfg.data_dir, \"test\")\n",
    "    print(\n",
    "        f\"Найдено: train={len(train_samples)} файлов, val={len(val_samples)} файлов, test={len(test_samples)} файлов\"\n",
    "    )\n",
    "    samples = list_dataset(cfg.data_dir)\n",
    "    if not samples:\n",
    "        raise RuntimeError(f\"В каталоге {cfg.data_dir} не найдены .png\")\n",
    "\n",
    "    train_samples, val_samples, test_samples = split_dataset(samples, cfg.train_ratio, cfg.val_ratio, cfg.seed)\n",
    "    print(f\"Разбиение: train={len(train_samples)}, val={len(val_samples)}, test={len(test_samples)}\")\n",
    "\n",
    "    train_ds = YoloTxtDataset(train_samples)\n",
    "    val_ds = YoloTxtDataset(val_samples)\n",
    "    test_ds = YoloTxtDataset(test_samples)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True,\n",
    "                              num_workers=cfg.num_workers, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False,\n",
    "                            num_workers=cfg.num_workers, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_ds, batch_size=cfg.batch_size, shuffle=False,\n",
    "                             num_workers=cfg.num_workers, collate_fn=collate_fn)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = build_model(num_classes=1 + 1)  # один класс объекта + фон\n",
    "    model.to(device)\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.AdamW(params, lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "    history: Dict[str, List[float]] = {\"train_loss\": [], \"val_map\": []}\n",
    "\n",
    "    for epoch in range(cfg.num_epochs):\n",
    "        losses = train_one_epoch(model, optimizer, train_loader, device)\n",
    "        mean_loss = sum(losses) / len(losses)\n",
    "        history[\"train_loss\"].append(mean_loss)\n",
    "        print(f\"Эпоха {epoch+1}/{cfg.num_epochs}: средний train loss = {mean_loss:.4f}\")\n",
    "\n",
    "        val_metrics = evaluate_map(model, val_loader, device)\n",
    "        if val_metrics and \"map\" in val_metrics:\n",
    "            history[\"val_map\"].append(val_metrics[\"map\"].item())\n",
    "            print(f\"mAP@0.5: {val_metrics['map']:.4f}\")\n",
    "        else:\n",
    "            history[\"val_map\"].append(float(\"nan\"))\n",
    "\n",
    "    os.makedirs(cfg.output_dir, exist_ok=True)\n",
    "    torch.save({\"model_state\": model.state_dict(), \"config\": asdict(cfg)}, os.path.join(cfg.output_dir, \"model.pt\"))\n",
    "    print(f\"Модель сохранена в {cfg.output_dir}/model.pt\")\n",
    "\n",
    "    # Финальная оценка на тестовой выборке\n",
    "    test_metrics = evaluate_map(model, test_loader, device)\n",
    "    if test_metrics:\n",
    "        print(\"Тестовые метрики:\", test_metrics)\n",
    "\n",
    "    plot_curves(history, cfg.output_dir)\n",
    "\n",
    "    return model, history, test_metrics\n",
    "\n"
    "    return model, history, test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример запуска в Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# DATA_DIR = '/content/drive/MyDrive/path/to/dataset'  # внутри уже есть train/val/test\n",
    "# cfg = TrainConfig(data_dir=DATA_DIR, output_dir='/content/drive/MyDrive/rcnn_runs', num_epochs=5, batch_size=2)\n",
    "# model, history, test_metrics = run_training(cfg)\n",
    "\"\"\"После выполнения всех ячеек выше, настройте пути к данным и раскомментируйте пример, чтобы запустить обучение.\"\"\"\n",
    "\n"
    "# DATA_DIR = '/content/drive/MyDrive/path/to/dataset'\n",
    "# cfg = TrainConfig(data_dir=DATA_DIR, output_dir='/content/drive/MyDrive/rcnn_runs', num_epochs=5, batch_size=2)\n",
    "# model, history, test_metrics = run_training(cfg)\n",
    "\"\"\"После выполнения всех ячеек выше, настройте пути к данным и раскомментируйте пример, чтобы запустить обучение.\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
}
